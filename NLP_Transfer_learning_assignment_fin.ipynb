{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5el_8SqFqVAT"
      },
      "source": [
        "\n",
        "In this notebook, You will do amazon review classification with BERT.[Download data from [this](https://www.kaggle.com/snap/amazon-fine-food-reviews/data) link]\n",
        "<pre> \n",
        "It contains 5 parts as below.  Detailed instrctions are given in the each cell. please read every comment we have written. \n",
        "    1. Preprocessing \n",
        "    2. Creating a BERT model from the Tensorflow HUB.\n",
        "    3. Tokenization\n",
        "    4. getting the pretrained embedding Vector for a given review from the BERT.\n",
        "    5. Using the embedding data apply NN and classify the reviews.\n",
        "    6. Creating a Data pipeline for BERT Model. \n",
        "\n",
        "<font size=5>instructions:</font>\n",
        "\n",
        "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. \n",
        "    If you manipulate any, it will be considered as plagiarised. \n",
        "    \n",
        "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
        "    \n",
        "    3. please return outputs in the same format what we asked. Eg. Don't return List if we are asking for a numpy array.\n",
        "    \n",
        "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
        "    \n",
        "    5. We are giving instructions at each section if necessary, please follow them. \n",
        "\n",
        "<font size=5>Every Grader function has to return True. </font>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E6JSKPjKwOLP"
      },
      "outputs": [],
      "source": [
        "#in this assignment you need two files reviews.csv and tokenization file\n",
        "#you can use gdown module to import both the files in colab from Google drive\n",
        "#the syntax is for gdown is !gdown --id file_id\n",
        "#please run the below cell to import the required files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUGbEZafwwzX",
        "outputId": "84e65666-ecdd-4616-9d83-bb502ac7ade6"
      },
      "outputs": [],
      "source": [
        "# !gdown --id 1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt\n",
        "# !gdown --id 13exfXiyiByluh1PfYK1EyZyizqxeCVG9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wOtG4cf0qVAZ"
      },
      "outputs": [],
      "source": [
        "#all imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpu = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(gpu[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(r'D:\\Applied_AI\\Aass_28')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OcmiHdAJqVAi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBsay58AqVAo"
      },
      "source": [
        "<font size=4>Grader function 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aTBvOKFeqVAq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def grader_tf_version():\n",
        "    assert((tf.__version__)>'2')\n",
        "    return True\n",
        "grader_tf_version()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTWRqbrBqVAu"
      },
      "source": [
        "<pre><font size=6>Part-1: Preprocessing</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B3csZKDrqVAv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568438 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n"
          ]
        }
      ],
      "source": [
        "#Read the dataset - Amazon fine food reviews\n",
        "reviews = pd.read_csv(r\"Reviews.csv\")\n",
        "#check the info of the dataset\n",
        "reviews.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK      dll pa                     0   \n",
              "\n",
              "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
              "0                       1      5  1303862400  Good Quality Dog Food   \n",
              "1                       0      1  1346976000      Not as Advertised   \n",
              "\n",
              "                                                Text  \n",
              "0  I have bought several of the Vitality canned d...  \n",
              "1  Product arrived labeled as Jumbo Salted Peanut...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xokNn7qZqVAz"
      },
      "outputs": [],
      "source": [
        "#get only 2 columns - Text, Score\n",
        "#drop the NAN values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(                                                Text  Score\n",
              " 0  I have bought several of the Vitality canned d...      5\n",
              " 1  Product arrived labeled as Jumbo Salted Peanut...      1,\n",
              " (568454, 2))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = reviews[['Text','Score']]\n",
        "df.head(2),df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews = df.drop(df[df['Score']==3].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews.loc[reviews['Score'] < 3,'Score'] = 0\n",
        "reviews.loc[reviews['Score'] > 3,'Score'] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Score\n",
              "0  I have bought several of the Vitality canned d...      1\n",
              "1  Product arrived labeled as Jumbo Salted Peanut...      0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(525814, 2)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVe8LlkrqVA6"
      },
      "source": [
        "<font size=4>Grader function 2 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7mDXSiJpqVA7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def grader_reviews():\n",
        "    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n",
        "    assert(temp_shape == True)\n",
        "    return True\n",
        "grader_reviews()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xYZ-UB9UqVA-"
      },
      "outputs": [],
      "source": [
        "def get_wordlen(x):\n",
        "    return len(x.split())\n",
        "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
        "reviews = reviews[reviews.len<50]\n",
        "reviews = reviews.sample(n=100000, random_state=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CvldQriGqVBB"
      },
      "outputs": [],
      "source": [
        "#remove HTML from the Text column and save in the Text column only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "reviews['Text'] = [re.sub(r'<[^<]+?','', text) for text in reviews['Text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AhfN1s2mqVBD"
      },
      "outputs": [],
      "source": [
        "#print head 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64117</th>\n",
              "      <td>The tea was of great quality and it tasted lik...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418112</th>\n",
              "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357829</th>\n",
              "      <td>Great product. Does not completely get rid of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175872</th>\n",
              "      <td>This gum is my favorite!  I would advise every...</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178716</th>\n",
              "      <td>I also found out about this product because of...</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Text  Score  len\n",
              "64117   The tea was of great quality and it tasted lik...      1   30\n",
              "418112  My cat loves this.  The pellets are nice and s...      1   31\n",
              "357829  Great product. Does not completely get rid of ...      1   41\n",
              "175872  This gum is my favorite!  I would advise every...      1   27\n",
              "178716  I also found out about this product because of...      1   22"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NsYDd3okqVBF"
      },
      "outputs": [],
      "source": [
        "#split the data into train and test data(20%) with Stratify sampling, random state 33, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = reviews.drop(['Score'],axis=1)\n",
        "y = reviews['Score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64117</th>\n",
              "      <td>The tea was of great quality and it tasted lik...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418112</th>\n",
              "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Text  len\n",
              "64117   The tea was of great quality and it tasted lik...   30\n",
              "418112  My cat loves this.  The pellets are nice and s...   31"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64117     1\n",
              "418112    1\n",
              "Name: Score, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=33,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((80000, 2), (20000, 2), (80000,), (20000,))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-Q6OAcrOqVBI"
      },
      "outputs": [],
      "source": [
        "#plot bar graphs of y_train and y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "data_tr = {'y_tr_class_1':y_train.value_counts()[1],'y_tr_class_0':y_train.value_counts()[0]}\n",
        "data_te = {'y_te_class_1':y_test.value_counts()[1],'y_te_class_0':y_test.value_counts()[0]}\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "bar1 = plt.bar(data_tr.keys(),data_tr.values(),width=0.35)\n",
        "bar2 = plt.bar(data_te.keys(),data_te.values(),width=0.35)\n",
        "\n",
        "plt.xlabel('Class distribution',fontsize = 15)\n",
        "plt.ylabel('values',fontsize = 15)\n",
        "plt.title('Graph of data distribution',fontsize = 20)\n",
        "plt.legend((bar1,bar2),('y_train','y_test'))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Up-z5boWqVBK"
      },
      "outputs": [],
      "source": [
        "#saving to disk. if we need, we can load preprocessed data directly. \n",
        "reviews.to_csv('preprocessed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBtqNGN9qVBM"
      },
      "source": [
        "<pre><font size=6>Part-2: Creating BERT Model</font> \n",
        "\n",
        "If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n",
        "we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n",
        "\n",
        "\n",
        "For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
        "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "i8xd2HejqVBN"
      },
      "outputs": [],
      "source": [
        "## Loading the Pretrained Model from tensorflow HUB\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
        "max_seq_length = 55\n",
        "\n",
        "#BERT takes 3 inputs\n",
        "\n",
        "#this is input words. Sequence of words represented as integers\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "\n",
        "#mask vector if you are padding anything\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "\n",
        "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
        "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
        "#second seq segment vector are 1's\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "#bert layer \n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "#Bert model\n",
        "#We are using only pooled output not sequence out. \n",
        "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
        "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lQJsjg6fqVBQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 109,482,241\n",
            "Trainable params: 0\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "bert_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "w3z0OMA5qVBS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_model.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewv4hFCsqVBU"
      },
      "source": [
        "<pre><font size=6>Part-3: Tokenization</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tX3VEFjiqVBU"
      },
      "outputs": [],
      "source": [
        "#getting Vocab file\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\Applied_AI\\\\Aass_28'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conda install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Y_iPwa99qVBW"
      },
      "outputs": [],
      "source": [
        "import tokenization #We have given tokenization.py file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "guJMLJ8bqVBY"
      },
      "outputs": [],
      "source": [
        "# Create tokenizer \" Instantiate FullTokenizer\" \n",
        "# name must be \"tokenizer\"\n",
        "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
        "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
        "# please check the \"tokenization.py\" file the complete implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qlGFtp2xxzt6"
      },
      "outputs": [],
      "source": [
        "# if you are getting error for sentencepiece module you can install it using below command while running this cell for the first time\n",
        "#!pip install sentencepiece\n",
        "tokenizer=tokenization.FullTokenizer(vocab_file,do_lower_case )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKkGLhR-qVBd"
      },
      "source": [
        "<font size=4>Grader function 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2CPu850xqVBe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#it has to give no error \n",
        "def grader_tokenize(tokenizer):\n",
        "    out = False\n",
        "    try:\n",
        "        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n",
        "    except:\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "grader_tokenize(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9crhPylQqVBg"
      },
      "outputs": [],
      "source": [
        "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
        "\n",
        "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
        "\n",
        "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
        "\n",
        "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
        "\n",
        "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
        "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
        "\n",
        "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
        "\n",
        "# type of all the above arrays should be numpy arrays\n",
        "\n",
        "# after execution of this cell, you have to get \n",
        "# X_train_tokens, X_train_mask, X_train_segment\n",
        "# X_test_tokens, X_test_mask, X_test_segment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv1-t4OjqVBj"
      },
      "source": [
        "#### Example\n",
        "<img src='https://i.imgur.com/5AhhmgU.png'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I had never tried this brand before, so I was worried about the quality.  It tasted great.  A very nice smooth rich full flavor.  Its my new favoret.'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.values[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original sentence : \n",
            " ['I', 'had', 'never', 'tried', 'this', 'brand', 'before,', 'so', 'I', 'was', 'worried', 'about', 'the', 'quality.', 'It', 'tasted', 'great.', 'A', 'very', 'nice', 'smooth', 'rich', 'full', 'flavor.', 'Its', 'my', 'new', 'favoret.']\n",
            "Number of words :  28\n",
            "****************************************************************************************************\n",
            "tokens are : \n",
            " ['[CLS]', 'i', 'had', 'never', 'tried', 'this', 'brand', 'before', ',', 'so', 'i', 'was', 'worried', 'about', 'the', 'quality', '.', 'it', 'tasted', 'great', '.', 'a', 'very', 'nice', 'smooth', 'rich', 'full', 'flavor', '.', 'its', 'my', 'new', 'favor', '##et', '.', '[SEP]']\n",
            "****************************************************************************************************\n",
            "Number of tokens :  36\n",
            "tokens replaced with posional encoding : \n",
            " [  101  1045  2018  2196  2699  2023  4435  2077  1010  2061  1045  2001\n",
            "  5191  2055  1996  3737  1012  2009 12595  2307  1012  1037  2200  3835\n",
            "  5744  4138  2440 14894  1012  2049  2026  2047  5684  3388  1012   102]\n",
            "****************************************************************************************************\n",
            "the mask array is :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "****************************************************************************************************\n",
            "The segment array is :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "****************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "print('original sentence : \\n',X_train.values[0][0].split())\n",
        "print('Number of words : ',len(X_train.values[0][0].split()))\n",
        "print('*'*100)\n",
        "tokens = tokenizer.tokenize(X_train.values[0][0])\n",
        "tokens = tokens[:(max_seq_length-2)]\n",
        "tokens = ['[CLS]',*tokens,'[SEP]']\n",
        "print('tokens are : \\n',tokens) \n",
        "print('*'*100)\n",
        "print('Number of tokens : ',len(tokens))\n",
        "print('tokens replaced with posional encoding : \\n',np.array(tokenizer.convert_tokens_to_ids(tokens)))\n",
        "print('*'*100)\n",
        "print('the mask array is : ',np.array([1]*len(tokens)+[0]*(max_seq_length-len(tokens))))\n",
        "print('*'*100)\n",
        "print('The segment array is : ',np.array([0]*max_seq_length))\n",
        "print('*'*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.reset_index(inplace = True)\n",
        "X_test.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((80000,), (20000,))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_tr_txt = X_train.Text\n",
        "X_te_txt = X_test.Text\n",
        "X_tr_txt.shape,X_te_txt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def token():\n",
        "    X_train_tokens = []\n",
        "    X_test_tokens = []\n",
        "\n",
        "    X_train_mask = []\n",
        "    X_test_mask = []\n",
        "\n",
        "    X_train_segment = []\n",
        "    X_test_segment = []\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(len(X_tr_txt)):\n",
        "        tkn0 = tokenizer.tokenize(X_tr_txt.values[i])\n",
        "        if len(tkn0) < max_seq_length:\n",
        "            tkn1 = tkn0[0:(max_seq_length-2)]\n",
        "            tkn2 = ['[CLS]', *tkn1, '[SEP]']        \n",
        "            tokens = [*tkn2, *['[PAD]']*(max_seq_length-len(tkn2))]\n",
        "            mask = [*[1]*len(tkn2), *[0]*(max_seq_length-len(tkn2))]\n",
        "\n",
        "        elif len(tkn0) >= max_seq_length: \n",
        "            tkn1 = tkn0[0:(max_seq_length-2)]\n",
        "            tokens = ['[CLS]', *tkn1, '[SEP]']\n",
        "            mask = [*[1]*max_seq_length]\n",
        "        X_train_tokens.append(tokenizer.convert_tokens_to_ids(tokens))\n",
        "        X_train_mask.append(mask)\n",
        "        X_train_segment.append(np.array([0]*max_seq_length))\n",
        "\n",
        "    for i in range(len(X_te_txt)):\n",
        "        tkn0 = tokenizer.tokenize(X_te_txt.values[i])\n",
        "        if len(tkn0) < max_seq_length:\n",
        "            tkn1 = tkn0[0:(max_seq_length-2)]\n",
        "            tkn2 = ['[CLS]', *tkn1, '[SEP]']        \n",
        "            tokens = [*tkn2, *['[PAD]']*(max_seq_length-len(tkn2))]\n",
        "            mask = [*[1]*len(tkn2), *[0]*(max_seq_length-len(tkn2))]\n",
        "\n",
        "        elif len(tkn0) >= max_seq_length: \n",
        "            tkn1 = tkn0[0:(max_seq_length-2)]\n",
        "            tokens = ['[CLS]', *tkn1, '[SEP]']\n",
        "            mask = [*[1]*max_seq_length]\n",
        "        X_test_tokens.append(tokenizer.convert_tokens_to_ids(tokens))\n",
        "        X_test_mask.append(mask)\n",
        "        X_test_segment.append(np.array([0]*max_seq_length))\n",
        "    return np.array(X_train_tokens),np.array(X_test_tokens),np.array(X_train_mask),np.array(X_test_mask),np.array(X_train_segment),np.array(X_test_segment)\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        " X_train_tokens,X_test_tokens,X_train_mask,X_test_mask,X_train_segment,X_test_segment = token()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xF0idMRDqVBm"
      },
      "outputs": [],
      "source": [
        "##save all your results to disk so that, no need to run all again. \n",
        "import pickle\n",
        "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
        "pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Leu1URGzqVBo"
      },
      "outputs": [],
      "source": [
        "# you can load from disk\n",
        "import pickle\n",
        "X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
        "X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjPv8VkJqVBr"
      },
      "source": [
        "<font size=4>Grader function 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "qekHJgmdqVBs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def grader_alltokens_train():\n",
        "    out = False\n",
        "    \n",
        "    if type(X_train_tokens) == np.ndarray:\n",
        "        \n",
        "        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n",
        "        (X_train_segment.shape[1]==max_seq_length)\n",
        "        \n",
        "        segment_temp = not np.any(X_train_segment)\n",
        "        \n",
        "        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n",
        "        \n",
        "        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n",
        "        \n",
        "        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n",
        "        \n",
        "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
        "      \n",
        "    else:\n",
        "        print('Type of all above token arrays should be numpy array not list')\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "\n",
        "grader_alltokens_train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnvC6X_wqVBu"
      },
      "source": [
        "<font size=4>Grader function 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Av4SRMPSqVBv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def grader_alltokens_test():\n",
        "    out = False\n",
        "    if type(X_test_tokens) == np.ndarray:\n",
        "        \n",
        "        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n",
        "        (X_test_segment.shape[1]==max_seq_length)\n",
        "        \n",
        "        segment_temp = not np.any(X_test_segment)\n",
        "        \n",
        "        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n",
        "        \n",
        "        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n",
        "        \n",
        "        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n",
        "        \n",
        "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
        "      \n",
        "    else:\n",
        "        print('Type of all above token arrays should be numpy array not list')\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "grader_alltokens_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEj-Eua5qVBx"
      },
      "source": [
        "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
        "We already created the BERT model in the part-2 and input data in the part-3. \n",
        "We will utlize those two and will get the embeddings for each sentence in the \n",
        "Train and test data.</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QwOVgQFDqVBy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_word_ids')>,\n",
              " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_mask')>,\n",
              " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'segment_ids')>]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_model.input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZcpkQq1OqVB0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_model.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "IxdIlOIBlm7j"
      },
      "outputs": [],
      "source": [
        "# get the train output, BERT model will give one output so save in\n",
        "# X_train_pooled_output\n",
        "#this cell will take some time to execute, make sure thay you have stable internet connection\n",
        "X_train_pooled_output=bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "yZT11BCol4gL"
      },
      "outputs": [],
      "source": [
        "# get the test output, BERT model will give one output so save in\n",
        "# X_test_pooled_output\n",
        "X_test_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "DL6JVojfqVB8"
      },
      "outputs": [],
      "source": [
        "##save all your results to disk so that, no need to run all again. \n",
        "pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oSQcBdROqVB9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulEXFE7aqVCA"
      },
      "source": [
        "<font size=4>Grader function 6 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "oHCsW0IvqVCB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#now we have X_train_pooled_output, y_train\n",
        "#X_test_pooled_ouput, y_test\n",
        "\n",
        "#please use this grader to evaluate\n",
        "def greader_output():\n",
        "    assert(X_train_pooled_output.shape[1]==768)\n",
        "    assert(len(y_train)==len(X_train_pooled_output))\n",
        "    assert(X_test_pooled_output.shape[1]==768)\n",
        "    assert(len(y_test)==len(X_test_pooled_output))\n",
        "    assert(len(y_train.shape)==1)\n",
        "    assert(len(X_train_pooled_output.shape)==2)\n",
        "    assert(len(y_test.shape)==1)\n",
        "    assert(len(X_test_pooled_output.shape)==2)\n",
        "    return True\n",
        "greader_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYwS1QbAqVCD"
      },
      "source": [
        "<pre><font size=6>Part-5: Training a NN with 768 features</font>\n",
        "\n",
        "Create a NN and train the NN. \n",
        "1.<b> You have to use AUC as metric. Do not use tf.keras.metrics.AUC</b> \n",
        "<b> You have to write custom code for AUC and print it at the end of each epoch</b> \n",
        "2. You can use any architecture you want. \n",
        "3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n",
        "4. Print the loss and metric at every epoch. \n",
        "5. You have to submit without overfitting and underfitting. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "od8PQlYRqVCE"
      },
      "outputs": [],
      "source": [
        "##imports\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DSnmX3WnqVCG"
      },
      "outputs": [],
      "source": [
        "##create an Neural Network and train your model on X_train_pooled_output and y_train\n",
        "# you can start as follows\n",
        "#input_layer=Input(shape=(X_train_pooled_output.shape[1],))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def auroc(y_tr, y_pred):\n",
        "    return tf.py_function(auc, (y_tr, y_pred), tf.double)\n",
        "\n",
        "def auc(y_train, y_pred):\n",
        "    if len(np.unique(y_train[:,1])) == 1:\n",
        "        return 0.5\n",
        "    else:\n",
        "        return roc_auc_score(y_train, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "y_train_nw = np_utils.to_categorical(y_train, 2) \n",
        "y_test_nw = np_utils.to_categorical(y_test, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import regularizers\n",
        "from keras.initializers import he_normal\n",
        "from keras.layers import LSTM, SpatialDropout1D, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,Reshape, Conv1D\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Conv3D, MaxPool2D, Flatten, Conv2D, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "input=Input(shape=(X_train_pooled_output.shape[1],))\n",
        "output = Dense(2, activation='softmax', name='output')(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# . When padding=\"same\" and strides=1, the output has the same size as the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2)                 1538      \n",
            "=================================================================\n",
            "Total params: 1,538\n",
            "Trainable params: 1,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1 = Model(inputs=[input], outputs=[output])\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm -rf ./logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(r'D:\\Applied_AI\\Aass_28\\New folder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\"NLP_tr_learn.h5\", monitor=\"val_auroc\", mode=\"max\", save_best_only=True, verbose=2)\n",
        "earlystop = EarlyStopping(monitor = 'val_auroc', patience = 3, mode=\"max\",min_delta = 0, verbose = 2)\n",
        "logs = 'logs4'\n",
        "tensorboard = TensorBoard(log_dir=logs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1.compile(loss='categorical_crossentropy', optimizer='Adam',  metrics=[auroc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1250/1250 [==============================] - 8s 5ms/step - loss: 0.2903 - auroc: 0.8653 - val_loss: 0.2428 - val_auroc: 0.9150\n",
            "\n",
            "Epoch 00001: val_auroc improved from -inf to 0.91500, saving model to NLP_tr_learn.h5\n",
            "Epoch 2/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2276 - auroc: 0.9290 - val_loss: 0.2165 - val_auroc: 0.9308\n",
            "\n",
            "Epoch 00002: val_auroc improved from 0.91500 to 0.93076, saving model to NLP_tr_learn.h5\n",
            "Epoch 3/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2109 - auroc: 0.9381 - val_loss: 0.2053 - val_auroc: 0.9362\n",
            "\n",
            "Epoch 00003: val_auroc improved from 0.93076 to 0.93617, saving model to NLP_tr_learn.h5\n",
            "Epoch 4/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2023 - auroc: 0.9424 - val_loss: 0.2046 - val_auroc: 0.9382\n",
            "\n",
            "Epoch 00004: val_auroc improved from 0.93617 to 0.93824, saving model to NLP_tr_learn.h5\n",
            "Epoch 5/30\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.1963 - auroc: 0.9444 - val_loss: 0.2032 - val_auroc: 0.9397\n",
            "\n",
            "Epoch 00005: val_auroc improved from 0.93824 to 0.93974, saving model to NLP_tr_learn.h5\n",
            "Epoch 6/30\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.1935 - auroc: 0.9464 - val_loss: 0.1943 - val_auroc: 0.9413\n",
            "\n",
            "Epoch 00006: val_auroc improved from 0.93974 to 0.94134, saving model to NLP_tr_learn.h5\n",
            "Epoch 7/30\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.1911 - auroc: 0.9473 - val_loss: 0.1948 - val_auroc: 0.9431\n",
            "\n",
            "Epoch 00007: val_auroc improved from 0.94134 to 0.94312, saving model to NLP_tr_learn.h5\n",
            "Epoch 8/30\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1872 - auroc: 0.9480 - val_loss: 0.1894 - val_auroc: 0.9440\n",
            "\n",
            "Epoch 00008: val_auroc improved from 0.94312 to 0.94399, saving model to NLP_tr_learn.h5\n",
            "Epoch 9/30\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1861 - auroc: 0.9495 - val_loss: 0.2008 - val_auroc: 0.9447\n",
            "\n",
            "Epoch 00009: val_auroc improved from 0.94399 to 0.94471, saving model to NLP_tr_learn.h5\n",
            "Epoch 10/30\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1853 - auroc: 0.9495 - val_loss: 0.1922 - val_auroc: 0.9453\n",
            "\n",
            "Epoch 00010: val_auroc improved from 0.94471 to 0.94527, saving model to NLP_tr_learn.h5\n",
            "Epoch 11/30\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1842 - auroc: 0.9496 - val_loss: 0.1921 - val_auroc: 0.9464\n",
            "\n",
            "Epoch 00011: val_auroc improved from 0.94527 to 0.94640, saving model to NLP_tr_learn.h5\n",
            "Epoch 12/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1828 - auroc: 0.9512 - val_loss: 0.1843 - val_auroc: 0.9462\n",
            "\n",
            "Epoch 00012: val_auroc did not improve from 0.94640\n",
            "Epoch 13/30\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1816 - auroc: 0.9513 - val_loss: 0.1901 - val_auroc: 0.9471\n",
            "\n",
            "Epoch 00013: val_auroc improved from 0.94640 to 0.94710, saving model to NLP_tr_learn.h5\n",
            "Epoch 14/30\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.1813 - auroc: 0.9520 - val_loss: 0.1946 - val_auroc: 0.9463\n",
            "\n",
            "Epoch 00014: val_auroc did not improve from 0.94710\n",
            "Epoch 15/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1798 - auroc: 0.9526 - val_loss: 0.1843 - val_auroc: 0.9471\n",
            "\n",
            "Epoch 00015: val_auroc did not improve from 0.94710\n",
            "Epoch 16/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1791 - auroc: 0.9532 - val_loss: 0.1843 - val_auroc: 0.9482\n",
            "\n",
            "Epoch 00016: val_auroc improved from 0.94710 to 0.94819, saving model to NLP_tr_learn.h5\n",
            "Epoch 17/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1786 - auroc: 0.9525 - val_loss: 0.1829 - val_auroc: 0.9485\n",
            "\n",
            "Epoch 00017: val_auroc improved from 0.94819 to 0.94848, saving model to NLP_tr_learn.h5\n",
            "Epoch 18/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1781 - auroc: 0.9530 - val_loss: 0.1837 - val_auroc: 0.9488\n",
            "\n",
            "Epoch 00018: val_auroc improved from 0.94848 to 0.94878, saving model to NLP_tr_learn.h5\n",
            "Epoch 19/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1767 - auroc: 0.9535 - val_loss: 0.1854 - val_auroc: 0.9492\n",
            "\n",
            "Epoch 00019: val_auroc improved from 0.94878 to 0.94917, saving model to NLP_tr_learn.h5\n",
            "Epoch 20/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1771 - auroc: 0.9533 - val_loss: 0.1886 - val_auroc: 0.9493\n",
            "\n",
            "Epoch 00020: val_auroc improved from 0.94917 to 0.94934, saving model to NLP_tr_learn.h5\n",
            "Epoch 21/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1764 - auroc: 0.9541 - val_loss: 0.1797 - val_auroc: 0.9493\n",
            "\n",
            "Epoch 00021: val_auroc improved from 0.94934 to 0.94934, saving model to NLP_tr_learn.h5\n",
            "Epoch 22/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1769 - auroc: 0.9539 - val_loss: 0.1785 - val_auroc: 0.9498\n",
            "\n",
            "Epoch 00022: val_auroc improved from 0.94934 to 0.94981, saving model to NLP_tr_learn.h5\n",
            "Epoch 23/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1761 - auroc: 0.9551 - val_loss: 0.1831 - val_auroc: 0.9495\n",
            "\n",
            "Epoch 00023: val_auroc did not improve from 0.94981\n",
            "Epoch 24/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1750 - auroc: 0.9551 - val_loss: 0.1777 - val_auroc: 0.9501\n",
            "\n",
            "Epoch 00024: val_auroc improved from 0.94981 to 0.95012, saving model to NLP_tr_learn.h5\n",
            "Epoch 25/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1750 - auroc: 0.9552 - val_loss: 0.1789 - val_auroc: 0.9500\n",
            "\n",
            "Epoch 00025: val_auroc did not improve from 0.95012\n",
            "Epoch 26/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1741 - auroc: 0.9542 - val_loss: 0.1768 - val_auroc: 0.9505\n",
            "\n",
            "Epoch 00026: val_auroc improved from 0.95012 to 0.95052, saving model to NLP_tr_learn.h5\n",
            "Epoch 27/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1733 - auroc: 0.9551 - val_loss: 0.1828 - val_auroc: 0.9508\n",
            "\n",
            "Epoch 00027: val_auroc improved from 0.95052 to 0.95075, saving model to NLP_tr_learn.h5\n",
            "Epoch 28/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1731 - auroc: 0.9551 - val_loss: 0.1761 - val_auroc: 0.9510\n",
            "\n",
            "Epoch 00028: val_auroc improved from 0.95075 to 0.95100, saving model to NLP_tr_learn.h5\n",
            "Epoch 29/30\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.1736 - auroc: 0.9559 - val_loss: 0.1792 - val_auroc: 0.9506\n",
            "\n",
            "Epoch 00029: val_auroc did not improve from 0.95100\n",
            "Epoch 30/30\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1723 - auroc: 0.9558 - val_loss: 0.1767 - val_auroc: 0.9511\n",
            "\n",
            "Epoch 00030: val_auroc improved from 0.95100 to 0.95108, saving model to NLP_tr_learn.h5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x25213119eb0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.fit(X_train_pooled_output,\n",
        "    y_train_nw,\n",
        "    epochs=30,\n",
        "    validation_data=(X_test_pooled_output, y_test_nw),\n",
        "    batch_size=64,\n",
        "    verbose=True,\n",
        "    callbacks=[checkpoint,earlystop,tensorboard])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 14340), started 0:00:04 ago. (Use '!kill 14340' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-cb74870141f4eeec\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-cb74870141f4eeec\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part-6: Creating a Data pipeline for BERT Model \n",
        "1. Pipeline is a way to codify and automate the workflow.\n",
        "2. Download the test.csv file from here here "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_74n3sgFjvlM"
      },
      "outputs": [],
      "source": [
        "#there is an alterante way to load files from Google drive directly to your Colab session\n",
        "# you can use gdown module to import the files as follows\n",
        "#for example for test.csv you can write your code as !gdown --id file_id (remove the # from next line and run it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(r'D:\\Applied_AI\\Aass_28')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lQcoHbUKjgvF"
      },
      "outputs": [],
      "source": [
        "#read the csv file\n",
        "test_df= pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zii6hgejdhQ"
      },
      "source": [
        "<Pre>1. You have to write a function that takes the test_df,trained model and the required parameters as input. \n",
        "2. Perform all the preproceesing steps inside the function.\n",
        "- Remove all the html tags\n",
        "- Now do tokenization [Part 3 as mentioned above]\n",
        "- Create tokens,mask array and segment array\n",
        "- Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n",
        "- Print the shape of output(X_test.shape).You should get (352,768)\n",
        "3. Predit the output of X_test with the neural network model which we trained earlier.\n",
        "\n",
        "4. Return the occurences of class labels from the function.\n",
        "The output should be the count of datapoints classified as 1 or 0.\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "g9g6C_kgjcan"
      },
      "outputs": [],
      "source": [
        "class Transformer:\n",
        "\n",
        "  def __init__(self, test_data, classifier):\n",
        "    self.test_data = test_data\n",
        "    self.classifier = classifier\n",
        "\n",
        "  def pre_process(self, test_data):\n",
        "    def remove_html_tag(file):\n",
        "      sent = re.sub(r'(<.*>)' , '', file)\n",
        "      return sent\n",
        "    self.test_data['Text'] = self.test_data['Text'].apply(remove_html_tag)\n",
        "    \n",
        "    tokens_test = []\n",
        "    mask_test = []\n",
        "    segment_test = []\n",
        "    for i in range(len(self.test_data)):\n",
        "        tkn0 = tokenizer.tokenize(self.test_data['Text'].values[i])\n",
        "        if len(tkn0) >= max_seq_length:    \n",
        "            tkn1 = tkn0[0:(max_seq_length-2)]\n",
        "            tokens = ['[CLS]', *tkn1, '[SEP]']\n",
        "            mask = [*[1]*max_seq_length]\n",
        "        elif len(tkn0) < max_seq_length:\n",
        "            tkn1 = tkn0[0:(max_seq_length-2)]\n",
        "            tokens2 = ['[CLS]', *tkn1, '[SEP]']        \n",
        "            tokens = [*tokens2, *['[PAD]']*(max_seq_length-len(tokens2))]\n",
        "            mask = [*[1]*len(tokens2), *[0]*(max_seq_length-len(tokens2))]\n",
        "        tokens_test.append(tokenizer.convert_tokens_to_ids(tokens))\n",
        "        mask_test.append(mask)\n",
        "        segment_test.append(np.array([0]*max_seq_length))\\\n",
        "\n",
        "    tok_test = np.array(tokens_test)\n",
        "    mas_test = np.array(mask_test)\n",
        "    seg_test = np.array(segment_test)\n",
        "    X_test = bert_model.predict([tok_test, mas_test, seg_test])\n",
        "#     print(X_test.shape)\n",
        "    return X_test\n",
        "    \n",
        "    # input_ = bert_layer.input_\n",
        "\n",
        "  def classifier(self, X_test):\n",
        "    return self.classifier.predict([X_test])\n",
        "\n",
        "  def predict_labels(self):\n",
        "    \n",
        "    input_ = self.pre_process(self.test_data)\n",
        "    output_ = self.classifier(input_)\n",
        "    return(output_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(352, 2), dtype=float32, numpy=\n",
              "array([[8.78480971e-01, 1.21518992e-01],\n",
              "       [3.61322938e-03, 9.96386766e-01],\n",
              "       [3.96517128e-01, 6.03482902e-01],\n",
              "       [1.87921837e-01, 8.12078118e-01],\n",
              "       [5.17334556e-03, 9.94826615e-01],\n",
              "       [4.52210009e-01, 5.47789991e-01],\n",
              "       [8.83625150e-01, 1.16374850e-01],\n",
              "       [1.31705194e-03, 9.98682916e-01],\n",
              "       [1.05842995e-03, 9.98941600e-01],\n",
              "       [1.14572828e-03, 9.98854280e-01],\n",
              "       [3.67057294e-01, 6.32942677e-01],\n",
              "       [1.15615381e-02, 9.88438427e-01],\n",
              "       [7.63591051e-01, 2.36408919e-01],\n",
              "       [2.49335572e-01, 7.50664413e-01],\n",
              "       [7.28447139e-02, 9.27155256e-01],\n",
              "       [9.86350358e-01, 1.36496825e-02],\n",
              "       [2.14633346e-03, 9.97853696e-01],\n",
              "       [1.22743961e-03, 9.98772562e-01],\n",
              "       [3.60623859e-02, 9.63937581e-01],\n",
              "       [3.14159580e-02, 9.68584061e-01],\n",
              "       [1.35752678e-01, 8.64247382e-01],\n",
              "       [6.84313551e-02, 9.31568623e-01],\n",
              "       [2.24997163e-01, 7.75002897e-01],\n",
              "       [1.21272385e-01, 8.78727615e-01],\n",
              "       [5.01172729e-02, 9.49882686e-01],\n",
              "       [1.38372357e-03, 9.98616219e-01],\n",
              "       [2.82567972e-03, 9.97174263e-01],\n",
              "       [5.78488149e-02, 9.42151189e-01],\n",
              "       [8.34990591e-02, 9.16500866e-01],\n",
              "       [7.41444528e-03, 9.92585599e-01],\n",
              "       [7.04717934e-01, 2.95282066e-01],\n",
              "       [1.66539848e-01, 8.33460152e-01],\n",
              "       [6.79670135e-03, 9.93203282e-01],\n",
              "       [4.96410066e-03, 9.95035827e-01],\n",
              "       [3.31642814e-02, 9.66835737e-01],\n",
              "       [5.58330430e-05, 9.99944210e-01],\n",
              "       [6.61440909e-01, 3.38559091e-01],\n",
              "       [5.05427597e-03, 9.94945705e-01],\n",
              "       [4.22463706e-03, 9.95775402e-01],\n",
              "       [3.00027523e-03, 9.96999681e-01],\n",
              "       [9.38619554e-01, 6.13804571e-02],\n",
              "       [4.76629473e-04, 9.99523401e-01],\n",
              "       [1.66980792e-02, 9.83301938e-01],\n",
              "       [2.58974694e-02, 9.74102557e-01],\n",
              "       [9.04989541e-01, 9.50103998e-02],\n",
              "       [2.72660106e-01, 7.27339923e-01],\n",
              "       [4.70368890e-03, 9.95296299e-01],\n",
              "       [2.65820891e-01, 7.34179139e-01],\n",
              "       [4.73351311e-03, 9.95266557e-01],\n",
              "       [2.22689025e-02, 9.77731049e-01],\n",
              "       [3.72886565e-03, 9.96271133e-01],\n",
              "       [6.65088221e-02, 9.33491230e-01],\n",
              "       [1.13522238e-03, 9.98864770e-01],\n",
              "       [9.18704391e-01, 8.12955871e-02],\n",
              "       [8.69473398e-01, 1.30526558e-01],\n",
              "       [1.95012405e-03, 9.98049855e-01],\n",
              "       [3.81875634e-02, 9.61812437e-01],\n",
              "       [1.23085985e-02, 9.87691343e-01],\n",
              "       [1.82412483e-03, 9.98175859e-01],\n",
              "       [1.44210004e-03, 9.98557866e-01],\n",
              "       [1.59408376e-02, 9.84059095e-01],\n",
              "       [4.51764527e-06, 9.99995470e-01],\n",
              "       [1.94432512e-02, 9.80556726e-01],\n",
              "       [6.89033568e-02, 9.31096613e-01],\n",
              "       [4.19487618e-02, 9.58051264e-01],\n",
              "       [3.90351415e-02, 9.60964859e-01],\n",
              "       [1.13562557e-04, 9.99886394e-01],\n",
              "       [6.21021679e-03, 9.93789732e-01],\n",
              "       [7.34264217e-03, 9.92657363e-01],\n",
              "       [2.69844364e-02, 9.73015487e-01],\n",
              "       [5.58019243e-02, 9.44198072e-01],\n",
              "       [2.70776497e-03, 9.97292221e-01],\n",
              "       [2.07818046e-01, 7.92181969e-01],\n",
              "       [8.83187284e-04, 9.99116838e-01],\n",
              "       [7.86111970e-03, 9.92138922e-01],\n",
              "       [6.46944270e-02, 9.35305595e-01],\n",
              "       [5.22057666e-03, 9.94779468e-01],\n",
              "       [1.86809272e-01, 8.13190699e-01],\n",
              "       [3.25196749e-03, 9.96748090e-01],\n",
              "       [5.51621756e-03, 9.94483769e-01],\n",
              "       [2.03390699e-03, 9.97966170e-01],\n",
              "       [9.91100252e-01, 8.89973342e-03],\n",
              "       [3.03891003e-01, 6.96108997e-01],\n",
              "       [5.40540695e-01, 4.59459335e-01],\n",
              "       [6.61322773e-01, 3.38677198e-01],\n",
              "       [9.79694664e-01, 2.03053467e-02],\n",
              "       [4.15959984e-01, 5.84040046e-01],\n",
              "       [1.37365263e-04, 9.99862671e-01],\n",
              "       [2.20907200e-02, 9.77909327e-01],\n",
              "       [4.73057106e-02, 9.52694356e-01],\n",
              "       [1.15902647e-02, 9.88409758e-01],\n",
              "       [1.95880890e-01, 8.04119051e-01],\n",
              "       [1.15659591e-02, 9.88434017e-01],\n",
              "       [5.49470680e-03, 9.94505227e-01],\n",
              "       [3.73064075e-03, 9.96269345e-01],\n",
              "       [3.75226815e-03, 9.96247709e-01],\n",
              "       [9.95689571e-01, 4.31042537e-03],\n",
              "       [9.01638865e-02, 9.09836113e-01],\n",
              "       [6.35794625e-02, 9.36420560e-01],\n",
              "       [4.09212755e-03, 9.95907903e-01],\n",
              "       [2.36330274e-03, 9.97636676e-01],\n",
              "       [5.40323695e-03, 9.94596720e-01],\n",
              "       [3.42680351e-03, 9.96573210e-01],\n",
              "       [3.13399732e-01, 6.86600327e-01],\n",
              "       [1.18215131e-02, 9.88178551e-01],\n",
              "       [1.07755614e-02, 9.89224374e-01],\n",
              "       [1.46310544e-02, 9.85368907e-01],\n",
              "       [1.61259621e-02, 9.83873963e-01],\n",
              "       [5.63344322e-02, 9.43665624e-01],\n",
              "       [1.27324775e-01, 8.72675240e-01],\n",
              "       [3.52085638e-03, 9.96479213e-01],\n",
              "       [3.90214589e-03, 9.96097803e-01],\n",
              "       [1.50614360e-04, 9.99849319e-01],\n",
              "       [2.83577340e-03, 9.97164190e-01],\n",
              "       [5.83789870e-03, 9.94162142e-01],\n",
              "       [3.82630602e-02, 9.61736917e-01],\n",
              "       [5.93982451e-02, 9.40601766e-01],\n",
              "       [3.68167497e-02, 9.63183284e-01],\n",
              "       [1.82502363e-02, 9.81749773e-01],\n",
              "       [1.46871544e-02, 9.85312879e-01],\n",
              "       [1.40798220e-04, 9.99859214e-01],\n",
              "       [2.99821608e-02, 9.70017910e-01],\n",
              "       [9.15721834e-01, 8.42781663e-02],\n",
              "       [7.19748018e-03, 9.92802441e-01],\n",
              "       [4.53709206e-03, 9.95462954e-01],\n",
              "       [1.14533061e-03, 9.98854637e-01],\n",
              "       [9.20678116e-03, 9.90793169e-01],\n",
              "       [5.21363039e-03, 9.94786382e-01],\n",
              "       [1.02852941e-01, 8.97147000e-01],\n",
              "       [2.19316825e-01, 7.80683219e-01],\n",
              "       [3.80521029e-01, 6.19479001e-01],\n",
              "       [5.38190842e-01, 4.61809188e-01],\n",
              "       [1.99146313e-03, 9.98008549e-01],\n",
              "       [5.53939268e-02, 9.44606066e-01],\n",
              "       [2.23389752e-02, 9.77661014e-01],\n",
              "       [2.73339115e-02, 9.72666085e-01],\n",
              "       [7.00810105e-02, 9.29919004e-01],\n",
              "       [3.36858094e-01, 6.63141847e-01],\n",
              "       [1.18136173e-03, 9.98818576e-01],\n",
              "       [1.37799814e-01, 8.62200201e-01],\n",
              "       [8.72582383e-03, 9.91274178e-01],\n",
              "       [7.69012749e-01, 2.30987251e-01],\n",
              "       [3.18688676e-02, 9.68131065e-01],\n",
              "       [1.17309820e-02, 9.88268971e-01],\n",
              "       [9.59022995e-03, 9.90409732e-01],\n",
              "       [3.10862297e-03, 9.96891439e-01],\n",
              "       [5.52800670e-03, 9.94472027e-01],\n",
              "       [4.33637321e-01, 5.66362679e-01],\n",
              "       [1.56154400e-02, 9.84384537e-01],\n",
              "       [5.07891439e-02, 9.49210823e-01],\n",
              "       [2.75958469e-03, 9.97240424e-01],\n",
              "       [1.95652649e-01, 8.04347396e-01],\n",
              "       [2.18925212e-04, 9.99781072e-01],\n",
              "       [6.37409883e-03, 9.93625879e-01],\n",
              "       [2.39094645e-02, 9.76090550e-01],\n",
              "       [4.80386019e-01, 5.19613981e-01],\n",
              "       [6.89824519e-04, 9.99310136e-01],\n",
              "       [1.58355795e-02, 9.84164417e-01],\n",
              "       [8.31858039e-01, 1.68141916e-01],\n",
              "       [3.78779739e-01, 6.21220231e-01],\n",
              "       [2.65918858e-03, 9.97340858e-01],\n",
              "       [2.29934864e-02, 9.77006495e-01],\n",
              "       [9.31870285e-03, 9.90681350e-01],\n",
              "       [8.44447222e-03, 9.91555512e-01],\n",
              "       [1.94520541e-02, 9.80547905e-01],\n",
              "       [1.29955192e-03, 9.98700380e-01],\n",
              "       [1.85136087e-02, 9.81486380e-01],\n",
              "       [6.61742687e-02, 9.33825731e-01],\n",
              "       [7.73808802e-04, 9.99226213e-01],\n",
              "       [1.24929869e-03, 9.98750687e-01],\n",
              "       [6.34202361e-02, 9.36579764e-01],\n",
              "       [7.14048557e-03, 9.92859483e-01],\n",
              "       [4.11958486e-01, 5.88041484e-01],\n",
              "       [3.73010188e-02, 9.62698936e-01],\n",
              "       [9.90695119e-01, 9.30489507e-03],\n",
              "       [7.13449845e-04, 9.99286592e-01],\n",
              "       [1.76922604e-02, 9.82307792e-01],\n",
              "       [4.81792510e-01, 5.18207490e-01],\n",
              "       [2.24600174e-02, 9.77540016e-01],\n",
              "       [1.51866609e-02, 9.84813392e-01],\n",
              "       [8.48844469e-01, 1.51155472e-01],\n",
              "       [8.14075246e-02, 9.18592513e-01],\n",
              "       [3.17513914e-04, 9.99682546e-01],\n",
              "       [8.60865135e-03, 9.91391301e-01],\n",
              "       [1.61331818e-02, 9.83866811e-01],\n",
              "       [1.21916018e-01, 8.78083944e-01],\n",
              "       [4.37500417e-01, 5.62499583e-01],\n",
              "       [8.21263254e-01, 1.78736731e-01],\n",
              "       [1.04043866e-02, 9.89595592e-01],\n",
              "       [7.79060304e-01, 2.20939696e-01],\n",
              "       [1.57133967e-03, 9.98428643e-01],\n",
              "       [2.04210058e-01, 7.95789957e-01],\n",
              "       [2.50970684e-02, 9.74902928e-01],\n",
              "       [6.50850649e-04, 9.99349177e-01],\n",
              "       [2.11421683e-01, 7.88578391e-01],\n",
              "       [4.61358041e-01, 5.38641989e-01],\n",
              "       [7.94231668e-02, 9.20576811e-01],\n",
              "       [1.51452012e-02, 9.84854758e-01],\n",
              "       [1.84324920e-01, 8.15675080e-01],\n",
              "       [1.70645770e-03, 9.98293579e-01],\n",
              "       [2.37102695e-02, 9.76289690e-01],\n",
              "       [8.02415772e-04, 9.99197543e-01],\n",
              "       [3.29056494e-02, 9.67094302e-01],\n",
              "       [1.44395586e-02, 9.85560477e-01],\n",
              "       [9.78117576e-04, 9.99021888e-01],\n",
              "       [2.68828822e-03, 9.97311711e-01],\n",
              "       [2.17800742e-04, 9.99782264e-01],\n",
              "       [5.56691252e-02, 9.44330871e-01],\n",
              "       [1.01438044e-02, 9.89856243e-01],\n",
              "       [4.85838950e-02, 9.51416075e-01],\n",
              "       [1.75199541e-03, 9.98247981e-01],\n",
              "       [1.19926864e-02, 9.88007307e-01],\n",
              "       [1.39109045e-01, 8.60890925e-01],\n",
              "       [4.26986837e-04, 9.99573052e-01],\n",
              "       [2.21955225e-01, 7.78044760e-01],\n",
              "       [2.62931306e-02, 9.73706841e-01],\n",
              "       [1.17854876e-02, 9.88214493e-01],\n",
              "       [1.04452735e-02, 9.89554763e-01],\n",
              "       [2.36252928e-03, 9.97637510e-01],\n",
              "       [7.80162122e-03, 9.92198408e-01],\n",
              "       [3.00104124e-03, 9.96999025e-01],\n",
              "       [6.31501973e-01, 3.68497998e-01],\n",
              "       [1.22724613e-02, 9.87727523e-01],\n",
              "       [6.11210053e-05, 9.99938846e-01],\n",
              "       [5.13699430e-04, 9.99486327e-01],\n",
              "       [5.08759141e-01, 4.91240889e-01],\n",
              "       [2.34611630e-01, 7.65388429e-01],\n",
              "       [6.57476842e-01, 3.42523098e-01],\n",
              "       [1.95471700e-02, 9.80452776e-01],\n",
              "       [3.19094793e-03, 9.96809065e-01],\n",
              "       [9.74254489e-01, 2.57455092e-02],\n",
              "       [1.04599190e-03, 9.98953938e-01],\n",
              "       [9.19830024e-01, 8.01699311e-02],\n",
              "       [4.82601486e-03, 9.95173991e-01],\n",
              "       [9.76543408e-04, 9.99023438e-01],\n",
              "       [9.42672968e-01, 5.73270954e-02],\n",
              "       [1.29463375e-02, 9.87053692e-01],\n",
              "       [5.00647500e-02, 9.49935198e-01],\n",
              "       [6.89442232e-02, 9.31055784e-01],\n",
              "       [6.38778090e-01, 3.61221880e-01],\n",
              "       [5.39028406e-01, 4.60971624e-01],\n",
              "       [4.00339859e-03, 9.95996594e-01],\n",
              "       [3.98492813e-03, 9.96015012e-01],\n",
              "       [1.45240920e-03, 9.98547614e-01],\n",
              "       [2.70893812e-01, 7.29106188e-01],\n",
              "       [9.00005162e-01, 9.99948010e-02],\n",
              "       [9.74324718e-03, 9.90256786e-01],\n",
              "       [1.53158074e-02, 9.84684169e-01],\n",
              "       [8.61320868e-02, 9.13867891e-01],\n",
              "       [9.52981412e-03, 9.90470171e-01],\n",
              "       [9.41288292e-01, 5.87117225e-02],\n",
              "       [3.37719335e-03, 9.96622801e-01],\n",
              "       [1.87664870e-02, 9.81233478e-01],\n",
              "       [2.12900341e-03, 9.97871041e-01],\n",
              "       [1.67739578e-02, 9.83226001e-01],\n",
              "       [6.82944477e-01, 3.17055523e-01],\n",
              "       [7.04322127e-04, 9.99295712e-01],\n",
              "       [9.54101145e-01, 4.58988734e-02],\n",
              "       [8.98402154e-01, 1.01597913e-01],\n",
              "       [5.05577177e-02, 9.49442267e-01],\n",
              "       [1.50409411e-03, 9.98495936e-01],\n",
              "       [9.51677084e-01, 4.83229496e-02],\n",
              "       [1.24035917e-01, 8.75964105e-01],\n",
              "       [4.71724244e-03, 9.95282710e-01],\n",
              "       [7.35091139e-03, 9.92649019e-01],\n",
              "       [2.99271080e-03, 9.97007310e-01],\n",
              "       [1.11567214e-01, 8.88432801e-01],\n",
              "       [2.11092900e-03, 9.97889102e-01],\n",
              "       [7.49211712e-03, 9.92507875e-01],\n",
              "       [1.47197372e-03, 9.98528004e-01],\n",
              "       [7.32919341e-03, 9.92670774e-01],\n",
              "       [9.22923923e-01, 7.70760477e-02],\n",
              "       [1.91119616e-04, 9.99808848e-01],\n",
              "       [7.77739137e-02, 9.22226071e-01],\n",
              "       [2.78089079e-03, 9.97219086e-01],\n",
              "       [2.09595505e-02, 9.79040384e-01],\n",
              "       [1.10795675e-02, 9.88920510e-01],\n",
              "       [2.67548207e-03, 9.97324467e-01],\n",
              "       [6.82043359e-02, 9.31795657e-01],\n",
              "       [1.26158550e-01, 8.73841465e-01],\n",
              "       [5.38864697e-04, 9.99461114e-01],\n",
              "       [2.03273389e-02, 9.79672670e-01],\n",
              "       [1.55760329e-02, 9.84423935e-01],\n",
              "       [6.02726312e-03, 9.93972719e-01],\n",
              "       [1.55236968e-03, 9.98447657e-01],\n",
              "       [6.14594901e-04, 9.99385357e-01],\n",
              "       [6.45134179e-03, 9.93548691e-01],\n",
              "       [3.90380695e-02, 9.60961998e-01],\n",
              "       [1.15051828e-02, 9.88494813e-01],\n",
              "       [1.06402778e-03, 9.98935997e-01],\n",
              "       [6.56381175e-02, 9.34361935e-01],\n",
              "       [6.54705167e-01, 3.45294803e-01],\n",
              "       [9.56964865e-03, 9.90430295e-01],\n",
              "       [1.21977469e-02, 9.87802207e-01],\n",
              "       [1.03153810e-01, 8.96846235e-01],\n",
              "       [3.70473176e-01, 6.29526794e-01],\n",
              "       [4.47634188e-03, 9.95523691e-01],\n",
              "       [1.49901018e-01, 8.50098968e-01],\n",
              "       [3.49798094e-04, 9.99650240e-01],\n",
              "       [2.81754415e-03, 9.97182488e-01],\n",
              "       [2.13566665e-02, 9.78643358e-01],\n",
              "       [6.00072145e-01, 3.99927825e-01],\n",
              "       [6.71743155e-01, 3.28256875e-01],\n",
              "       [7.84541853e-03, 9.92154539e-01],\n",
              "       [1.23491898e-01, 8.76508117e-01],\n",
              "       [2.24896837e-02, 9.77510273e-01],\n",
              "       [9.91223231e-02, 9.00877655e-01],\n",
              "       [9.89525914e-01, 1.04741305e-02],\n",
              "       [2.26224251e-02, 9.77377594e-01],\n",
              "       [4.31575686e-01, 5.68424284e-01],\n",
              "       [1.06990322e-01, 8.93009722e-01],\n",
              "       [3.28599242e-03, 9.96713996e-01],\n",
              "       [4.48299194e-04, 9.99551713e-01],\n",
              "       [5.78776717e-01, 4.21223283e-01],\n",
              "       [5.52207977e-03, 9.94477868e-01],\n",
              "       [3.09346314e-03, 9.96906579e-01],\n",
              "       [4.19008881e-02, 9.58099127e-01],\n",
              "       [4.40054312e-02, 9.55994606e-01],\n",
              "       [5.78502472e-03, 9.94214952e-01],\n",
              "       [5.24035236e-03, 9.94759619e-01],\n",
              "       [6.14878582e-03, 9.93851185e-01],\n",
              "       [2.90400144e-02, 9.70960021e-01],\n",
              "       [5.86629519e-03, 9.94133770e-01],\n",
              "       [4.92230415e-01, 5.07769644e-01],\n",
              "       [1.47300228e-01, 8.52699757e-01],\n",
              "       [7.16870502e-02, 9.28312957e-01],\n",
              "       [6.09275818e-01, 3.90724152e-01],\n",
              "       [9.28179026e-01, 7.18209520e-02],\n",
              "       [1.18343986e-03, 9.98816609e-01],\n",
              "       [2.68459171e-01, 7.31540859e-01],\n",
              "       [2.86070141e-03, 9.97139335e-01],\n",
              "       [3.79505724e-01, 6.20494306e-01],\n",
              "       [9.98085663e-02, 9.00191486e-01],\n",
              "       [1.85806230e-02, 9.81419444e-01],\n",
              "       [7.46535184e-03, 9.92534637e-01],\n",
              "       [2.96132197e-03, 9.97038722e-01],\n",
              "       [9.50355642e-03, 9.90496397e-01],\n",
              "       [7.39710499e-03, 9.92602885e-01],\n",
              "       [7.53373315e-04, 9.99246597e-01],\n",
              "       [2.82334629e-02, 9.71766472e-01],\n",
              "       [2.76617050e-01, 7.23382890e-01],\n",
              "       [2.39318539e-03, 9.97606754e-01],\n",
              "       [7.77606061e-03, 9.92223859e-01],\n",
              "       [2.71506538e-03, 9.97284889e-01],\n",
              "       [7.08321342e-03, 9.92916822e-01],\n",
              "       [2.32699476e-02, 9.76730049e-01],\n",
              "       [6.65552080e-01, 3.34447950e-01],\n",
              "       [4.23339428e-03, 9.95766640e-01],\n",
              "       [3.57750175e-03, 9.96422470e-01],\n",
              "       [4.72499430e-02, 9.52750087e-01],\n",
              "       [3.96129908e-03, 9.96038675e-01],\n",
              "       [9.57111479e-04, 9.99042809e-01]], dtype=float32)>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "pipe_line = Transformer(test_df, model_1)\n",
        "pipe_line.predict_labels()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZc7XTQOxcIO"
      },
      "source": [
        "## Please write your observations at the end of notebook and  explain each and every step you followed in solving this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Observations\n",
        "### Part 1\n",
        "Step 1. Imported all files.\n",
        "\n",
        "Step 2. In prepocessing step we kept two columns i.e. 'Score' and 'Text'.\n",
        "\n",
        "Srep 3. Removed rows where score = 3 and assigned score = 0 and 1 for score <3 and score > 3 respectively.\n",
        "\n",
        "Step 4. Splitted data into train and test data sets.\n",
        "\n",
        "Step 5. From the bar graph we can observe that among class 1 and class 0, presense of class 1 is in heigher side.\n",
        "\n",
        "### Part2\n",
        "Step 1. In this section a model is built with input as \n",
        "1. input_eord_id\n",
        "2. input mask\n",
        "3. segment_ids\n",
        "\n",
        "### Part 3 (Tokenization)\n",
        "In this section we tokenize the input sentences (assigning unique values to each unique words present in sentences)\n",
        "\n",
        "### Part 4 (Getting embeddings from BRET Model)\n",
        "In this section each word is vectorised and converted into 768 dimensions numerical vectors. (BERT vwctor used for vectorization)\n",
        "\n",
        "### Part 5\n",
        "In this section a neural network model is created with two layers i.e. input and output layers.\n",
        "\n",
        "We chose \"catagorical_crossentrpy\" as loss moniter and 'Adam' as optimizer.\n",
        "From model output results we can find that after 30th epoch validation accuracy is near about 95.10 % which is quite impressive.\n",
        "\n",
        "From Tensorboard Plot we can observe that accuracy goes on increasing with increasing number of epochs and loss value goes on decreasing with increasing number of epochs.\n",
        "\n",
        "## Part 6\n",
        "Finally in the last section we created a pipeline, where all sort of  preprocessing, tokenization, masking, segmentation and embedding is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQfm5vO1xoVR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": " BERT- Assignment_modified.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('dl')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "66427cc265086e9e725f52d72b4e0359a197a3ecb3d374de18689e90b2271f99"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
